{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPcqmclon6gj4LkOlAJL0DJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "50f0d33add7a4bce905807f184d1cd88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3344b352f77402a9346fb6ce21dcb56",
              "IPY_MODEL_b34352da688b4ff4bcdd82144a023e9c",
              "IPY_MODEL_f1ddd53d4a44442a942b3f91b038d374"
            ],
            "layout": "IPY_MODEL_5fac1bb309ce484c9026820cee9b4bb3"
          }
        },
        "a3344b352f77402a9346fb6ce21dcb56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43ae1105dc874805b1efa73615bc513b",
            "placeholder": "​",
            "style": "IPY_MODEL_47727566a23b40c599a0fa6c518666aa",
            "value": "Generating train split: "
          }
        },
        "b34352da688b4ff4bcdd82144a023e9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11e495344f894d49b6410ebe5436026e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ca9c7ac7d834ccdb7a8c74c6e5b6aac",
            "value": 1
          }
        },
        "f1ddd53d4a44442a942b3f91b038d374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf3b3e4c623544508bf8564c89c7001e",
            "placeholder": "​",
            "style": "IPY_MODEL_18465ce7721e4d989833396d2b02ca5f",
            "value": " 9989/0 [00:00&lt;00:00, 138238.93 examples/s]"
          }
        },
        "5fac1bb309ce484c9026820cee9b4bb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43ae1105dc874805b1efa73615bc513b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47727566a23b40c599a0fa6c518666aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11e495344f894d49b6410ebe5436026e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6ca9c7ac7d834ccdb7a8c74c6e5b6aac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf3b3e4c623544508bf8564c89c7001e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18465ce7721e4d989833396d2b02ca5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f56a61cd8594a59b0359bef36cff82b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_200788db7ddb4f8aa8c23a5a7f453346",
              "IPY_MODEL_3b6759ad162e41e5830373602564e104",
              "IPY_MODEL_2adfe459577c4cbb9fcc615ca7825c38"
            ],
            "layout": "IPY_MODEL_ac72feb8421d4675b95ddda7b2ce5f99"
          }
        },
        "200788db7ddb4f8aa8c23a5a7f453346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87987ded5531407d830f998b43ddbfa8",
            "placeholder": "​",
            "style": "IPY_MODEL_f7b26b6aea6c423a90ceede1d0ef3408",
            "value": "Map: 100%"
          }
        },
        "3b6759ad162e41e5830373602564e104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e50822387434724a52323d0b5433b08",
            "max": 9989,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_364058df545941eea29e01cbf69b1fb4",
            "value": 9989
          }
        },
        "2adfe459577c4cbb9fcc615ca7825c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df181cf8e06f4b58a06fad995a1891b5",
            "placeholder": "​",
            "style": "IPY_MODEL_15bac91065744fad954b4f9117132875",
            "value": " 9989/9989 [00:04&lt;00:00, 2879.92 examples/s]"
          }
        },
        "ac72feb8421d4675b95ddda7b2ce5f99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87987ded5531407d830f998b43ddbfa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7b26b6aea6c423a90ceede1d0ef3408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e50822387434724a52323d0b5433b08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "364058df545941eea29e01cbf69b1fb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df181cf8e06f4b58a06fad995a1891b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15bac91065744fad954b4f9117132875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arionpap4/llm_ast/blob/main/AST_LLM_APap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install trl\n",
        "!pip install peft\n",
        "!pip install bitsandbytes\n"
      ],
      "metadata": {
        "id": "5QFcGXVFtjVA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea920dc5-7907-4bca-903a-8ae465f45430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.10/dist-packages (0.11.4)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl) (2.5.0+cu121)\n",
            "Requirement already satisfied: transformers>=4.40.0 in /usr/local/lib/python3.10/dist-packages (from trl) (4.44.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from trl) (0.34.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from trl) (3.0.2)\n",
            "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl) (0.8.14)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from trl) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.4.0->trl) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.40.0->trl) (0.24.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.40.0->trl) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.40.0->trl) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.40.0->trl) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.40.0->trl) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.40.0->trl) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.40.0->trl) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.40.0->trl) (4.66.5)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.9.3)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->trl) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.10.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.40.0->trl) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.40.0->trl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.40.0->trl) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.40.0->trl) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.18.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->trl) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2024.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets->trl) (0.2.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.5.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.34.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.44.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edl1L2N8rOdg",
        "outputId": "d8464fb8-2042-4df4-c991-d56fa8bfb6ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "actual_model = \"keeeeenw/MicroLlama\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(actual_model, trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(actual_model, trust_remote_code=True) #.cuda() no gpu use\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Check if GPU is available\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "# Set up the pipeline to use GPU (if available)\n",
        "text_generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=device)\n",
        "# Test the model with arithmetic expressions\n",
        "equations = [\n",
        "    \"3 * 5 + 2 =\",\n",
        "    \"(4 + 6) * 2 =\",\n",
        "    \"10 / 2 + 8 =\",\n",
        "    \"7 * (3 + 2) =\"\n",
        "]\n",
        "\n",
        "# Generate outputs for each equation\n",
        "for equation in equations:\n",
        "    output = text_generator(equation, max_length=20, do_sample=True, temperature=0.7)\n",
        "    print(f\"Prompt: {equation}\")\n",
        "    print(f\"Model's Output: {output[0]['generated_text']}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sTYzXqOrWLZ",
        "outputId": "a9b607f8-d771-49dd-8525-1318697fbb4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: 3 * 5 + 2 =\n",
            "Model's Output: 3 * 5 + 2 = 100.\n",
            "\n",
            "A: \n",
            "--------------------------------------------------\n",
            "Prompt: (4 + 6) * 2 =\n",
            "Model's Output: (4 + 6) * 2 = 8.\n",
            "  # [12\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: 10 / 2 + 8 =\n",
            "Model's Output: 10 / 2 + 8 = 10 / 2 + 8\n",
            "--------------------------------------------------\n",
            "Prompt: 7 * (3 + 2) =\n",
            "Model's Output: 7 * (3 + 2) = 10.\n",
            "We can see the\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Function to generate a random arithmetic expression with optional brackets\n",
        "def generate_equation_with_brackets():\n",
        "    # Choose random numbers and operators\n",
        "    num1 = random.randint(1, 10)\n",
        "    num2 = random.randint(1, 10)\n",
        "    num3 = random.randint(1, 10)\n",
        "    operators = ['+', '-', '*', '/']\n",
        "\n",
        "    # Randomly pick operators\n",
        "    op1 = random.choice(operators)\n",
        "    op2 = random.choice(operators)\n",
        "\n",
        "    # Randomly decide where to place brackets (if at all)\n",
        "    bracket_positions = random.choice([\n",
        "        f\"({num1} {op1} {num2}) {op2} {num3}\",  # Brackets around the first part\n",
        "        f\"{num1} {op1} ({num2} {op2} {num3})\",  # Brackets around the second part\n",
        "        f\"({num1} {op1} {num2} {op2} {num3})\",  # Brackets around the entire expression\n",
        "        f\"{num1} {op1} {num2} {op2} {num3}\"     # No brackets\n",
        "    ])\n",
        "\n",
        "    # Evaluate the result using eval\n",
        "    try:\n",
        "        result = eval(bracket_positions)\n",
        "    except ZeroDivisionError:\n",
        "        result = None\n",
        "\n",
        "    # Return the expression and its result\n",
        "    return bracket_positions, result\n",
        "\n",
        "# Generate a few samples\n",
        "for _ in range(10):\n",
        "    expr, res = generate_equation_with_brackets()\n",
        "    if res is not None:  # Skip expressions with division by zero\n",
        "        print(f\"{expr} = {res}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16uJuBEFrbYo",
        "outputId": "52562ec1-2afe-4a07-a80f-4c29448d9b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9 - 10 + 1) = 0\n",
            "4 / (8 + 8) = 0.25\n",
            "3 * (9 + 2) = 33\n",
            "1 + 3 - 7 = -3\n",
            "(10 * 3 / 8) = 3.75\n",
            "(6 * 9 - 8) = 46\n",
            "(1 - 9 * 6) = -53\n",
            "(6 / 4 * 9) = 13.5\n",
            "(5 + 1 + 2) = 8\n",
            "6 - 2 * 2 = 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Generate a list of arithmetic equations with brackets for training\n",
        "training_data_with_brackets = []\n",
        "for _ in range(10000):  # Generate 1000 samples\n",
        "    expr, res = generate_equation_with_brackets()\n",
        "    if res is not None:\n",
        "        training_data_with_brackets.append({\"prompt\": expr, \"response\": f\"= {res}\"})\n",
        "\n",
        "# Save the data to a JSON file\n",
        "with open(\"arithmetic_training_data_with_brackets.json\", \"w\") as f:\n",
        "    json.dump(training_data_with_brackets, f)\n",
        "\n",
        "# Download the file to your local system\n",
        "from google.colab import files\n",
        "files.download(\"arithmetic_training_data_with_brackets.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "nOJEgeatrdmD",
        "outputId": "ae62701b-baa5-49da-8b77-f00b96e179d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_49e80ac2-f762-47e8-9afd-eff720355c59\", \"arithmetic_training_data_with_brackets.json\", 496957)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "\n",
        "# Set the pad_token to eos_token if no explicit pad_token is available\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "def tokenize_function(examples):\n",
        "    # Tokenize the input (prompt) and output (response) sequences\n",
        "    tokenized_inputs = tokenizer(examples['prompt'], padding='max_length', truncation=True, max_length=512)\n",
        "    tokenized_responses = tokenizer(examples['response'], padding='max_length', truncation=True, max_length=512)\n",
        "\n",
        "    # Create labels that match the input length\n",
        "    # Labels for the prompt part are set to -100, and the response part will have the tokenized response\n",
        "    labels = [-100] * len(tokenized_inputs['input_ids'])  # Mask out the input (prompt)\n",
        "    labels[len(tokenized_inputs['input_ids']) - len(tokenized_responses['input_ids']):] = tokenized_responses['input_ids']\n",
        "\n",
        "    return {\n",
        "        'input_ids': tokenized_inputs['input_ids'],\n",
        "        'attention_mask': tokenized_inputs['attention_mask'],\n",
        "        'labels': labels  # Ensure labels match input length\n",
        "    }\n",
        "\n",
        "\n",
        "# Load your custom dataset (assuming the data is in JSON format)\n",
        "dataset_folder = \"/content/arithmetic_training_data_with_brackets.json\"  # Path to your JSON file\n",
        "dataset = load_dataset('json', data_files=dataset_folder, split=\"train\")\n",
        "print(dataset)\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)  # This should return a Dataset object\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154,
          "referenced_widgets": [
            "50f0d33add7a4bce905807f184d1cd88",
            "a3344b352f77402a9346fb6ce21dcb56",
            "b34352da688b4ff4bcdd82144a023e9c",
            "f1ddd53d4a44442a942b3f91b038d374",
            "5fac1bb309ce484c9026820cee9b4bb3",
            "43ae1105dc874805b1efa73615bc513b",
            "47727566a23b40c599a0fa6c518666aa",
            "11e495344f894d49b6410ebe5436026e",
            "6ca9c7ac7d834ccdb7a8c74c6e5b6aac",
            "cf3b3e4c623544508bf8564c89c7001e",
            "18465ce7721e4d989833396d2b02ca5f",
            "5f56a61cd8594a59b0359bef36cff82b",
            "200788db7ddb4f8aa8c23a5a7f453346",
            "3b6759ad162e41e5830373602564e104",
            "2adfe459577c4cbb9fcc615ca7825c38",
            "ac72feb8421d4675b95ddda7b2ce5f99",
            "87987ded5531407d830f998b43ddbfa8",
            "f7b26b6aea6c423a90ceede1d0ef3408",
            "0e50822387434724a52323d0b5433b08",
            "364058df545941eea29e01cbf69b1fb4",
            "df181cf8e06f4b58a06fad995a1891b5",
            "15bac91065744fad954b4f9117132875"
          ]
        },
        "id": "9CPX9TeGO-is",
        "outputId": "5da1bbf2-0d91-49e9-c609-76964577500c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50f0d33add7a4bce905807f184d1cd88"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['prompt', 'response'],\n",
            "    num_rows: 9989\n",
            "})\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/9989 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f56a61cd8594a59b0359bef36cff82b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "# Define a data collator for language modeling, which dynamically pads to the longest sequence in a batch\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False,  # Set to False because you're training a causal language model (not masked language modeling)\n",
        ")\n"
      ],
      "metadata": {
        "id": "bEz-XafoTxfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and evaluation sets\n",
        "split_datasets = tokenized_dataset.train_test_split(test_size=0.2)\n",
        "\n",
        "# Separate train and eval datasets\n",
        "train_dataset = split_datasets['train']\n",
        "eval_dataset = split_datasets['test']\n"
      ],
      "metadata": {
        "id": "rgEponWFQz2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(eval_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsncpNDaKmGl",
        "outputId": "7dd5761e-d4c2-434c-8192-13f2a44b5a14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup, EarlyStoppingCallback\n",
        "\n",
        "# Define training arguments with improvements\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",                 # Output directory\n",
        "    evaluation_strategy=\"epoch\",            # Evaluate after each epoch\n",
        "    logging_strategy=\"steps\",               # Log training loss after a few steps\n",
        "    logging_steps=50,                       # Log every 50 steps\n",
        "    learning_rate=5e-5,                     # Initial learning rate\n",
        "    num_train_epochs=10,                    # Increase number of epochs\n",
        "    per_device_train_batch_size=4,          # Decrease batch size to avoid memory issues\n",
        "    per_device_eval_batch_size=4,           # Decrease evaluation batch size\n",
        "    gradient_accumulation_steps=2,          # Accumulate gradients over 2 steps to simulate larger batch size\n",
        "    weight_decay=0.01,                      # Weight decay to prevent overfitting\n",
        "    warmup_steps=500,                       # Warmup steps to gradually increase LR\n",
        "    lr_scheduler_type=\"linear\",             # Linear scheduler with warmup\n",
        "    save_strategy=\"epoch\",                  # Save checkpoint every epoch\n",
        "    save_total_limit=3,                     # Only save the 3 most recent checkpoints\n",
        "    fp16=True,                              # Enable mixed precision training\n",
        "    logging_dir=\"./logs\",                   # Directory for storing logs\n",
        "    load_best_model_at_end=True,            # Load the best model at the end of training\n",
        "    metric_for_best_model=\"eval_loss\",      # Use evaluation loss as the metric for best model\n",
        ")\n",
        "\n",
        "# Implement early stopping\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,      # Your training dataset\n",
        "    eval_dataset=eval_dataset,        # Your validation dataset\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],  # Early stopping\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "mjyfOGS0Njk2",
        "outputId": "91800f45-a17c-4308-fd2c-b12ed2572015"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1285' max='9990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1285/9990 15:07 < 1:42:35, 1.41 it/s, Epoch 1.29/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.382600</td>\n",
              "      <td>0.377413</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1482' max='9990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1482/9990 17:15 < 1:39:11, 1.43 it/s, Epoch 1.48/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.382600</td>\n",
              "      <td>0.377413</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-689b2251bc36>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1937\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1938\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1939\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1940\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2278\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2279\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2281\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3347\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3348\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3349\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3351\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2190\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2191\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2192\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2193\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_lomo_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2194\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments, get_linear_schedule_with_warmup, EarlyStoppingCallback\n",
        "\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",          # Output directory\n",
        "    evaluation_strategy=\"epoch\",     # Evaluate the model after each epoch\n",
        "    logging_strategy=\"steps\",        # Log training loss after every few steps\n",
        "    logging_steps=50,                # Log every 50 steps\n",
        "    learning_rate=5e-5,              # Learning rate for optimization\n",
        "    per_device_train_batch_size=8,   # Batch size for training\n",
        "    per_device_eval_batch_size=8,    # Batch size for evaluation\n",
        "    num_train_epochs=5,              # Number of training epochs\n",
        "    weight_decay=0.01,               # Weight decay to prevent overfitting\n",
        "    logging_dir=\"./logs\",            # Directory for storing logs\n",
        "    fp16=True,  # Enable mixed precision training\n",
        ")\n",
        "\n",
        "# Implement early stopping\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,      # Your training dataset\n",
        "    eval_dataset=eval_dataset,        # Your validation dataset\n",
        "   # callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],  # Early stopping\n",
        ")\n",
        "\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "UpfSQIPWQHvr",
        "outputId": "848d551f-74c8-4ebb-f66a-4972489ac267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  9/500 00:03 < 04:13, 1.94 it/s, Epoch 0.08/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-404d33fa932e>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1937\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1938\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1939\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1940\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2282\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2283\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2284\u001b[0;31m                     \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2285\u001b[0m                 ):\n\u001b[1;32m   2286\u001b[0m                     \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logs = trainer.state.log_history\n",
        "\n",
        "# Extract training and validation loss from logs\n",
        "train_loss = [log['loss'] for log in logs if 'loss' in log]\n",
        "val_loss = [log['eval_loss'] for log in logs if 'eval_loss' in log]\n",
        "# Extract the number of epochs for validation loss\n",
        "epochs = range(1, len(val_loss) + 1)\n",
        "\n",
        "# Plot the training and validation loss\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs, train_loss[:len(val_loss)], label='Training Loss')  # Slice training loss to match validation loss length\n",
        "plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training vs. Validation Loss')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "9BS2Nwzy_gPW",
        "outputId": "28093348-b505-40dd-dc43-77f11dbc5614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the fine-tuned model\n",
        "model.save_pretrained(\"./fine_tuned_microllama\")\n",
        "tokenizer.save_pretrained(\"./fine_tuned_microllama\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA7KTvYqRaeS",
        "outputId": "b1728f20-eea5-471d-d3d2-07d89c60da69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./fine_tuned_microllama/tokenizer_config.json',\n",
              " './fine_tuned_microllama/special_tokens_map.json',\n",
              " './fine_tuned_microllama/tokenizer.model',\n",
              " './fine_tuned_microllama/added_tokens.json',\n",
              " './fine_tuned_microllama/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\"./fine_tuned_microllama\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./fine_tuned_microllama\")\n",
        "\n",
        "# Set the device (GPU if available, otherwise CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Sample test data (prompt and expected response)\n",
        "test_data = [\n",
        "    {\"prompt\": \"3 + 5\", \"expected_response\": \"8\"},\n",
        "    {\"prompt\": \"10 - 2\", \"expected_response\": \"8\"},\n",
        "    {\"prompt\": \"(6 * 4) + 2\", \"expected_response\": \"26\"},\n",
        "]\n",
        "\n",
        "# Function to calculate accuracy\n",
        "def evaluate_model(model, tokenizer, test_data):\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for data in test_data:\n",
        "        prompt = data['prompt']\n",
        "        expected_response = data['expected_response']\n",
        "\n",
        "        # Tokenize and generate the model's response\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "        output = model.generate(inputs['input_ids'], attention_mask=inputs['attention_mask'], max_length=50, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "        # Decode the model's output and remove special tokens\n",
        "        generated_response = tokenizer.decode(output[0], skip_special_tokens=True).strip()\n",
        "\n",
        "        # Compare the generated response with the expected response\n",
        "        if generated_response == expected_response:\n",
        "            correct_predictions += 1\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = correct_predictions / len(test_data)\n",
        "    return accuracy\n",
        "\n",
        "# Evaluate the model's accuracy\n",
        "accuracy = evaluate_model(model, tokenizer, test_data)\n",
        "print(f\"Model accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUWhOm279Zv-",
        "outputId": "1e0caeed-c133-4af9-fa40-afc8590bf111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VOKV8bvEfCU",
        "outputId": "63422668-efd7-4aec-9ed5-f0491cd3805f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[    1, 29871, 29941,   718, 29871, 29945,   334, 29871, 29906]],\n",
            "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 1, 0, 0, 1, 1, 0, 1]], device='cuda:0')}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attention mask from ast"
      ],
      "metadata": {
        "id": "RDydrPGn-ASD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Function to parse input and generate AST\n",
        "def generate_ast(input_expression):\n",
        "    try:\n",
        "        tree = ast.parse(input_expression, mode='eval')  # 'eval' mode for expressions\n",
        "        return tree\n",
        "    except SyntaxError as e:\n",
        "        print(f\"Syntax Error in input: {input_expression}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "_ra2gRt_9_7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Traverse the AST and map tokens to attention mask\n",
        "class ASTVisitor(ast.NodeVisitor):\n",
        "    def __init__(self):\n",
        "        self.tokens_to_focus_on = []  # List to store important tokens\n",
        "\n",
        "    def visit_BinOp(self, node):\n",
        "        # Visit binary operation nodes and store operands and operator\n",
        "        self.tokens_to_focus_on.append(node.left)   # Operand (left side)\n",
        "        self.tokens_to_focus_on.append(node.op)     # Operator (+, -, *, etc.)\n",
        "        self.tokens_to_focus_on.append(node.right)  # Operand (right side)\n",
        "        self.generic_visit(node)\n",
        "\n",
        "    def visit_Num(self, node):\n",
        "        self.tokens_to_focus_on.append(node)\n",
        "\n",
        "    def visit_Constant(self, node):\n",
        "        self.tokens_to_focus_on.append(node)\n"
      ],
      "metadata": {
        "id": "_-FzMHcm-YYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Function to create an AST-based attention mask and map tokens to AST nodes\n",
        "def create_ast_attention_mask(tokenized_input, tokens_to_focus_on, tokenizer):\n",
        "    attention_mask = []\n",
        "    token_ast_map = []\n",
        "\n",
        "    # Extract tokens from the tokenized input\n",
        "    input_ids = tokenized_input['input_ids'][0]  # Assuming we are dealing with a batch of size 1\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "\n",
        "    # For each token in the tokenized input, check if it corresponds to an important token in the AST\n",
        "    for token_id in input_ids:\n",
        "        token_str = tokenizer.decode([token_id]).strip()\n",
        "\n",
        "        matched_node = None\n",
        "        attention_value = 0\n",
        "\n",
        "         # Map constants and numbers\n",
        "        if any(isinstance(node, (ast.Constant, ast.Num)) and str(node.value) == token_str for node in tokens_to_focus_on):\n",
        "            matched_node = f\"Constant: {token_str}\"\n",
        "            attention_value = 1  # Focus on this token\n",
        "\n",
        "        # Map all arithmetic operations\n",
        "        elif any(isinstance(node, ast.BinOp) and isinstance(node.op, ast.Add) and token_str == \"+\" for node in tokens_to_focus_on):\n",
        "            matched_node = \"Addition Operator\"\n",
        "            attention_value = 1  # Focus on addition\n",
        "        elif any(isinstance(node, ast.BinOp) and isinstance(node.op, ast.Sub) and token_str == \"-\" for node in tokens_to_focus_on):\n",
        "            matched_node = \"Subtraction Operator\"\n",
        "            attention_value = 1  # Focus on subtraction\n",
        "        elif any(isinstance(node, ast.BinOp) and isinstance(node.op, ast.Mult) and token_str == \"*\" for node in tokens_to_focus_on):\n",
        "            matched_node = \"Multiplication Operator\"\n",
        "            attention_value = 1  # Focus on multiplication\n",
        "        elif any(isinstance(node, ast.BinOp) and isinstance(node.op, ast.Div) and token_str == \"/\" for node in tokens_to_focus_on):\n",
        "            matched_node = \"Division Operator\"\n",
        "            attention_value = 1  # Focus on division\n",
        "        elif any(isinstance(node, ast.BinOp) and isinstance(node.op, ast.Mod) and token_str == \"%\" for node in tokens_to_focus_on):\n",
        "            matched_node = \"Modulus Operator\"\n",
        "            attention_value = 1  # Focus on modulus\n",
        "        elif any(isinstance(node, ast.BinOp) and isinstance(node.op, ast.Pow) and token_str == \"**\" for node in tokens_to_focus_on):\n",
        "            matched_node = \"Exponentiation Operator\"\n",
        "            attention_value = 1  # Focus on exponentiation\n",
        "        elif any(isinstance(node, ast.BinOp) and isinstance(node.op, ast.FloorDiv) and token_str == \"//\" for node in tokens_to_focus_on):\n",
        "            matched_node = \"Floor Division Operator\"\n",
        "            attention_value = 1  # Focus on floor division\n",
        "\n",
        "        # Add the result to the token-to-AST map and the attention mask\n",
        "        token_ast_map.append((token_str, matched_node))\n",
        "        attention_mask.append(attention_value)\n",
        "\n",
        "    return attention_mask, token_ast_map\n",
        "\n",
        "\n",
        "# Tokenize input and map tokens to AST nodes\n",
        "def tokenize_and_create_ast_attention_mask(prompt, tokenizer):\n",
        "\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "    # Tokenize the input prompt\n",
        "    tokenized_inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "    # Generate AST from the input expression\n",
        "    tree = generate_ast(prompt)\n",
        "\n",
        "    if tree is None:\n",
        "        return None, None  # Skip invalid expressions\n",
        "\n",
        "    # Visit AST and collect important tokens\n",
        "    visitor = ASTVisitor()\n",
        "    visitor.visit(tree)\n",
        "\n",
        "    # Create attention mask and map tokens to AST\n",
        "    attention_mask, token_ast_map = create_ast_attention_mask(tokenized_inputs, visitor.tokens_to_focus_on, tokenizer)\n",
        "\n",
        "    # Convert the attention mask into a tensor and reshape it correctly\n",
        "    attention_mask_tensor = torch.tensor(attention_mask).unsqueeze(0)  # Ensure correct shape: [1, seq_length]\n",
        "\n",
        "    # Add the attention mask to tokenized inputs\n",
        "    tokenized_inputs['attention_mask'] = attention_mask_tensor\n",
        "\n",
        "    return tokenized_inputs, token_ast_map"
      ],
      "metadata": {
        "id": "93AqjMo6-eI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize token-to-AST mapping and attention mask\n",
        "def visualize_token_ast_mapping(token_ast_map, attention_mask):\n",
        "    print(f\"{'Token':<10} | {'AST Node':<30} | {'Attention Mask':<15}\")\n",
        "    print(\"-\" * 60)\n",
        "    for idx, (token, ast_node) in enumerate(token_ast_map):\n",
        "        ast_node_str = ast_node if ast_node else \"None\"\n",
        "        print(f\"{token:<10} | {ast_node_str:<30} | {attention_mask[idx]:<15}\")"
      ],
      "metadata": {
        "id": "orkJM9FxD3Ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the fine-tuned model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\"./fine_tuned_microllama\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./fine_tuned_microllama\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Example prompt\n",
        "prompt = \"3 * 5 + 2 \"\n",
        "\n",
        "# Tokenize input and generate AST-based attention mask\n",
        "inputs, token_ast_map = tokenize_and_create_ast_attention_mask(prompt, tokenizer)\n",
        "\n",
        "# Move inputs to the device (GPU/CPU)\n",
        "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "# Print token-to-AST mapping and the corresponding attention mask\n",
        "visualize_token_ast_mapping(token_ast_map, inputs['attention_mask'][0].tolist())\n",
        "\n",
        "\"\"\"# Generate the response\n",
        "output = model.generate(inputs['input_ids'], attention_mask=inputs['attention_mask'], max_length=50)\n",
        "\n",
        "# Decode the generated response\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(\"\\nGenerated Text:\")\n",
        "print(generated_text)\n",
        "\"\"\"\n",
        "\n",
        "# Use top-k and top-p sampling to avoid repetitive output (adjustment in the sampling code)\n",
        "output = model.generate(\n",
        "    inputs['input_ids'],\n",
        "    attention_mask=inputs['attention_mask'],\n",
        "    max_length=50,\n",
        "    do_sample=True,         # Enable sampling to avoid greedy decoding\n",
        "    top_k=30,               # Lower top-k for less randomness\n",
        "    top_p=0.85,             # Lower top-p (nucleus) for more deterministic sampling\n",
        "    temperature=0.6,        # Lower temperature for more controlled output\n",
        "    pad_token_id=tokenizer.eos_token_id  # Ensure padding is handled correctly\n",
        ")\n",
        "\n",
        "# Decode the output and clean it up\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True).strip()\n",
        "\n",
        "\n",
        "print(f\"Question: {prompt}\")\n",
        "print(f\"Answer: {generated_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWxJDmRLDN-4",
        "outputId": "35966774-3139-4878-ebc6-54d64017f744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token      | AST Node                       | Attention Mask \n",
            "------------------------------------------------------------\n",
            "<s>        | None                           | 0              \n",
            "           | None                           | 0              \n",
            "3          | Constant: 3                    | 1              \n",
            "*          | Multiplication Operator        | 1              \n",
            "           | None                           | 0              \n",
            "5          | Constant: 5                    | 1              \n",
            "+          | None                           | 0              \n",
            "           | None                           | 0              \n",
            "2          | Constant: 2                    | 1              \n",
            "           | None                           | 0              \n",
            "Question: 3 * 5 + 2 \n",
            "Answer: = 3 * 5 + 2 1 *522 *523 *524 *525 *526 *527 *528 *529 *530 *53\n"
          ]
        }
      ]
    }
  ]
}